{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "shapes of train, validation, test data (569388, 128) (569388,) (142347, 128) (142347,) (237245, 128) (237245,)\nFrequency of distance values before sampling [1 2 3 4 5 6 7] [  6105 189469 307090  60097   6098    507     22]\n"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "x_train, y_train = pickle.load(open('../outputs/train_xy_no_sampling.pk', 'rb'))\n",
    "x_cv, y_cv = pickle.load(open('../outputs/val_xy_no_sampling.pk', 'rb'))\n",
    "x_test, y_test = pickle.load(open('../outputs/test_xy_no_sampling.pk', 'rb'))\n",
    "print('shapes of train, validation, test data', x_train.shape, y_train.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape)\n",
    "values, counts = np.unique(y_train, return_counts=True)\n",
    "print('Frequency of distance values before sampling', values, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-a0a7402e6bc7>, line 20)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-a0a7402e6bc7>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    over_sampler = KMeansSMOTE(sampling_strategy=oversample_dict, random_state=seed_random,n_jobs=15, k_neighbors: 5)\u001b[0m\n\u001b[1;37m                                                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "\n",
    "seed_random = 9999\n",
    "# max_idx = np.argmax(counts)\n",
    "# max_value = counts[max_idx]\n",
    "# majority_class = values[max_idx]\n",
    "\n",
    "x = int(counts[2]*0.5)\n",
    "y = int(0.62 * x)\n",
    "\n",
    "undersample_dict = {2:y, 3:x}\n",
    "under_sampler = ClusterCentroids(sampling_strategy=undersample_dict, random_state=seed_random, n_jobs=15)\n",
    "x_train, y_train = under_sampler.fit_resample(x_train, y_train.astype(np.int))\n",
    "print('Frequency of distance values after undersampling', np.unique(y_train, return_counts=True))\n",
    "\n",
    "minority_samples = int(0.6*x)\n",
    "oversample_dict = {1:minority_samples, 4:minority_samples, 5:minority_samples, 6:minority_samples, 7:minority_samples}\n",
    "over_sampler = KMeansSMOTE(sampling_strategy=oversample_dict, random_state=seed_random,n_jobs=15, k_neighbors= 5)\n",
    "x_train, y_train = over_sampler.fit_resample(x_train, y_train.astype(np.int))\n",
    "print('Frequency of distance values after oversampling', np.unique(y_train, return_counts=True))\n",
    "\n",
    "pickle.dump((x_train, y_train), open('../outputs/train_xy_combine_sampling.pk', 'wb'))\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_cv = scaler.transform(y_cv.reshape(-1, 1)).flatten()\n",
    "y_test = scaler.transform(y_test.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(999)\n",
    "x_train, y_train = unison_shuffle_copies(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  {'batch_size': 1000, 'input_size': 128, 'hidden_units_1': 256, 'hidden_units_2': 100, 'output_size': 1, 'lr': 0.001, 'min_lr': 1e-05, 'max_lr': 0.01, 'epochs': 700}\n",
    "# 0.00012 to 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "device: cuda:0\n"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data as torch_data\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "trainset = torch_data.TensorDataset(torch.as_tensor(x_train, dtype=torch.float, device=device), torch.as_tensor(y_train, dtype=torch.float, device=device))\n",
    "train_dl = torch_data.DataLoader(trainset, batch_size=params['batch_size'], drop_last=True)\n",
    "\n",
    "val_dl = torch_data.DataLoader(torch_data.TensorDataset(torch.as_tensor(x_cv, dtype=torch.float, device=device), torch.as_tensor(y_cv, dtype=torch.float, device=device)), batch_size=params['batch_size'], drop_last=True)\n",
    "\n",
    "test_dl = torch_data.DataLoader(torch_data.TensorDataset(torch.as_tensor(x_test, dtype=torch.float, device=device), torch.as_tensor(y_test, dtype=torch.float, device=device)), batch_size=params['batch_size'], drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "value counts in whole data (array([0.        , 0.16666667, 0.33333333, 0.5       , 0.66666667,\n       0.83333333, 1.        ]), array([203035, 202558, 290051, 203035, 203035, 203035, 203035],\n      dtype=int64))\n0 (0.0%) batches have all same targets\n"
    }
   ],
   "source": [
    "print('value counts in whole data', np.unique(y_train, return_counts=True))\n",
    "count = 0\n",
    "for i, data in enumerate(train_dl, 0):\n",
    "    input, target = data[0], data[1]\n",
    "    t = torch.unique(target, return_counts=True)[1]\n",
    "    if (t==params['batch_size']).any().item():\n",
    "        count += 1\n",
    "print('{} ({}%) batches have all same targets'.format(count, np.round(count/len(train_dl)*100, 2) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "model loaded into device= cuda:0\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Linear-1                  [-1, 256]          33,024\n              ReLU-2                  [-1, 256]               0\n            Linear-3                  [-1, 100]          25,700\n              ReLU-4                  [-1, 100]               0\n            Linear-5                    [-1, 1]             101\n              ReLU-6                    [-1, 1]               0\n================================================================\nTotal params: 58,825\nTrainable params: 58,825\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.01\nParams size (MB): 0.22\nEstimated Total Size (MB): 0.23\n----------------------------------------------------------------\n0.001\n"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "torch.manual_seed(9999)\n",
    "def get_model():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(params['input_size'], params['hidden_units_1']),\n",
    "        # torch.nn.Dropout(p=0.05),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_1'], params['hidden_units_2']),\n",
    "        # torch.nn.Dropout(p=0.04),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(params['hidden_units_2'], params['output_size']),\n",
    "        torch.nn.ReLU(),\n",
    "        # torch.nn.Softplus(),\n",
    "    )\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def poisson_loss(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Custom loss function for Poisson model.\n",
    "    Equivalent Keras implementation for reference:\n",
    "    K.mean(y_pred - y_true * math_ops.log(y_pred + K.epsilon()), axis=-1)\n",
    "    For output of shape (2,3) it return (2,) vector. Need to calculate\n",
    "    mean of that too.\n",
    "    \"\"\"\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    loss = torch.mean(y_pred - y_true * torch.log(y_pred+1e-7))\n",
    "    return loss\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "print('model loaded into device=', next(model.parameters()).device)\n",
    "summary(model, input_size=(128, ))\n",
    "\n",
    "lr_reduce_patience = 20\n",
    "lr_reduce_factor = 0.1\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "# loss_fn = torch.nn.L1Loss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params['lr'], momentum=0.9, dampening=0, weight_decay=0, nesterov=True)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=params['lr'], alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "\n",
    "lr_sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_reduce_factor, patience=lr_reduce_patience, verbose=True, threshold=0.00001, threshold_mode='rel', cooldown=0, min_lr=1e-9, eps=1e-08)\n",
    "# lr_sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=params['max_lr'], steps_per_epoch=len(train_dl), epochs=params['epochs'], div_factor=1e3)\n",
    "# lr_sched = torch.optim.lr_scheduler.CyclicLR(optimizer, params['min_lr'], params['max_lr'], step_size_up=8*len(train_dl), step_size_down=None, mode='triangular', last_epoch=-1)  # 1e-6, 1e-2, 4or8*len(train_dl), scale_mode=req for custom scale, last_epoch= num_of_iters_calculated--pass prev train iters if resuming \n",
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run next cell to find optimal range for learning rate while using One-Cycle LR scheduler\n",
    "In this case choosing the learning rate from graph below didn't help (same training speed as previoius range). Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from lr_range_finder import LrRangeFinder\n",
    "\n",
    "model.train()\n",
    "lr_range_finder = LrRangeFinder(len(train_dl), x=x_train, y=y_train, lr_low=params['lr'], lr_high=params['max_lr'])\n",
    "last_loss = None\n",
    "\n",
    "for i, data in enumerate(train_dl, 0):\n",
    "    # get the inputs; data is a list of [inputs, dist_true]\n",
    "    inputs, dist_true = data[0], data[1]\n",
    "    \n",
    "    # get loss for current iteration\n",
    "    curr_lr = lr_range_finder.get_next_lr(last_loss)\n",
    "    if not curr_lr:\n",
    "        break\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = curr_lr\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_fn(outputs, dist_true)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    last_loss = loss.item()\n",
    "\n",
    "lr_range_finder.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import math\n",
    "\n",
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(train_dl)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    for data in train_dl:\n",
    "        batch_num += 1\n",
    "        #As before, get the loss for this mini-batch of inputs/outputs\n",
    "        inputs, labels = data\n",
    "        # inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        #Do the SGD step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        #if batch_num % 10 == 0:\n",
    "        # print('batch_num:', batch_num, 'lr=', lr, 'smoothed_loss=', smoothed_loss, 'best_loss=', best_loss)\n",
    "    return log_lrs, losses\n",
    "\n",
    "lrs, losses = find_lr()\n",
    "print('returned')\n",
    "plt.figure()\n",
    "plt.plot(lrs, losses)\n",
    "plt.xticks(np.arange(min(lrs), max(lrs), 0.0001))\n",
    "plt.title('LR range plot')\n",
    "plt.xlabel('Learning rates')\n",
    "plt.ylabel('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    final_loss = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for data_cv in dl:\n",
    "            inputs, dist_true = data_cv[0], data_cv[1]\n",
    "            count += len(inputs)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, dist_true)\n",
    "            final_loss += loss.item()\n",
    "    return final_loss/len(dl)\n",
    "\n",
    "def save_checkpoint(state, state_save_path):\n",
    "    if not os.path.exists(\"/\".join(state_save_path.split('/')[:-1])):\n",
    "        os.makedirs(\"/\".join(state_save_path.split('/')[:-1]))\n",
    "    torch.save(state, state_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "total epochs= 700\nlr-check 0.001\n0 > Best val_loss model saved: 0.055\nepoch:0 -> train_loss=0.10804,val_loss=0.05486 - 0.0 minutes 49.0 seconds\n1 > Best val_loss model saved: 0.055\n2 > Best val_loss model saved: 0.055\n3 > Best val_loss model saved: 0.055\n4 > Best val_loss model saved: 0.055\n5 > Best val_loss model saved: 0.054\n6 > Best val_loss model saved: 0.054\n7 > Best val_loss model saved: 0.054\n8 > Best val_loss model saved: 0.054\n9 > Best val_loss model saved: 0.054\n10 > Best val_loss model saved: 0.054\nepoch:10 -> train_loss=0.10624,val_loss=0.05448 - 0.0 minutes 48.0 seconds\nepoch:20 -> train_loss=0.10623,val_loss=0.05448 - 0.0 minutes 47.0 seconds\nepoch:30 -> train_loss=0.10623,val_loss=0.05448 - 0.0 minutes 47.0 seconds\nEpoch    32: reducing learning rate of group 0 to 1.0000e-04.\n32 > Best val_loss model saved: 0.054\n33 > Best val_loss model saved: 0.054\n34 > Best val_loss model saved: 0.054\n35 > Best val_loss model saved: 0.054\n36 > Best val_loss model saved: 0.054\n37 > Best val_loss model saved: 0.054\n38 > Best val_loss model saved: 0.054\n39 > Best val_loss model saved: 0.054\n40 > Best val_loss model saved: 0.054\nepoch:40 -> train_loss=0.10623,val_loss=0.05369 - 0.0 minutes 47.0 seconds\n41 > Best val_loss model saved: 0.054\n42 > Best val_loss model saved: 0.054\n43 > Best val_loss model saved: 0.054\n44 > Best val_loss model saved: 0.054\n45 > Best val_loss model saved: 0.054\n46 > Best val_loss model saved: 0.054\n47 > Best val_loss model saved: 0.054\n48 > Best val_loss model saved: 0.054\n49 > Best val_loss model saved: 0.054\n50 > Best val_loss model saved: 0.054\nepoch:50 -> train_loss=0.10622,val_loss=0.05369 - 0.0 minutes 47.0 seconds\n51 > Best val_loss model saved: 0.054\n52 > Best val_loss model saved: 0.054\n53 > Best val_loss model saved: 0.054\n54 > Best val_loss model saved: 0.054\n55 > Best val_loss model saved: 0.054\n56 > Best val_loss model saved: 0.054\n57 > Best val_loss model saved: 0.054\n58 > Best val_loss model saved: 0.054\n59 > Best val_loss model saved: 0.054\n60 > Best val_loss model saved: 0.054\nepoch:60 -> train_loss=0.10622,val_loss=0.05369 - 0.0 minutes 50.0 seconds\n61 > Best val_loss model saved: 0.054\n62 > Best val_loss model saved: 0.054\n63 > Best val_loss model saved: 0.054\n64 > Best val_loss model saved: 0.054\n65 > Best val_loss model saved: 0.054\n66 > Best val_loss model saved: 0.054\n67 > Best val_loss model saved: 0.054\n68 > Best val_loss model saved: 0.054\n69 > Best val_loss model saved: 0.054\n70 > Best val_loss model saved: 0.054\nepoch:70 -> train_loss=0.10622,val_loss=0.05369 - 0.0 minutes 50.0 seconds\n71 > Best val_loss model saved: 0.054\n72 > Best val_loss model saved: 0.054\n73 > Best val_loss model saved: 0.054\n74 > Best val_loss model saved: 0.054\n75 > Best val_loss model saved: 0.054\n76 > Best val_loss model saved: 0.054\n77 > Best val_loss model saved: 0.054\n78 > Best val_loss model saved: 0.054\n79 > Best val_loss model saved: 0.054\n80 > Best val_loss model saved: 0.054\nepoch:80 -> train_loss=0.10622,val_loss=0.05369 - 0.0 minutes 47.0 seconds\n81 > Best val_loss model saved: 0.054\n82 > Best val_loss model saved: 0.054\n83 > Best val_loss model saved: 0.054\n84 > Best val_loss model saved: 0.054\n85 > Best val_loss model saved: 0.054\n86 > Best val_loss model saved: 0.054\n87 > Best val_loss model saved: 0.054\n88 > Best val_loss model saved: 0.054\n89 > Best val_loss model saved: 0.054\n90 > Best val_loss model saved: 0.054\nepoch:90 -> train_loss=0.10622,val_loss=0.05369 - 0.0 minutes 47.0 seconds\n91 > Best val_loss model saved: 0.054\n92 > Best val_loss model saved: 0.054\n93 > Best val_loss model saved: 0.054\n94 > Best val_loss model saved: 0.054\n95 > Best val_loss model saved: 0.054\n96 > Best val_loss model saved: 0.054\n97 > Best val_loss model saved: 0.054\n98 > Best val_loss model saved: 0.054\n99 > Best val_loss model saved: 0.054\n100 > Best val_loss model saved: 0.054\nepoch:100 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 50.0 seconds\n101 > Best val_loss model saved: 0.054\n102 > Best val_loss model saved: 0.054\n103 > Best val_loss model saved: 0.054\n104 > Best val_loss model saved: 0.054\n105 > Best val_loss model saved: 0.054\n106 > Best val_loss model saved: 0.054\n107 > Best val_loss model saved: 0.054\nepoch:110 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 50.0 seconds\n111 > Best val_loss model saved: 0.054\n112 > Best val_loss model saved: 0.054\n113 > Best val_loss model saved: 0.054\n114 > Best val_loss model saved: 0.054\n115 > Best val_loss model saved: 0.054\n116 > Best val_loss model saved: 0.054\n117 > Best val_loss model saved: 0.054\n118 > Best val_loss model saved: 0.054\n119 > Best val_loss model saved: 0.054\n120 > Best val_loss model saved: 0.054\nepoch:120 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 50.0 seconds\n121 > Best val_loss model saved: 0.054\n122 > Best val_loss model saved: 0.054\n123 > Best val_loss model saved: 0.054\n124 > Best val_loss model saved: 0.054\n125 > Best val_loss model saved: 0.054\n126 > Best val_loss model saved: 0.054\n127 > Best val_loss model saved: 0.054\n128 > Best val_loss model saved: 0.054\n129 > Best val_loss model saved: 0.054\n130 > Best val_loss model saved: 0.054\nepoch:130 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 50.0 seconds\n131 > Best val_loss model saved: 0.054\n132 > Best val_loss model saved: 0.054\n133 > Best val_loss model saved: 0.054\n134 > Best val_loss model saved: 0.054\n135 > Best val_loss model saved: 0.054\n136 > Best val_loss model saved: 0.054\n137 > Best val_loss model saved: 0.054\n138 > Best val_loss model saved: 0.054\n139 > Best val_loss model saved: 0.054\n140 > Best val_loss model saved: 0.054\nepoch:140 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 48.0 seconds\n141 > Best val_loss model saved: 0.054\n142 > Best val_loss model saved: 0.054\n143 > Best val_loss model saved: 0.054\n144 > Best val_loss model saved: 0.054\n145 > Best val_loss model saved: 0.054\n146 > Best val_loss model saved: 0.054\n147 > Best val_loss model saved: 0.054\n148 > Best val_loss model saved: 0.054\n149 > Best val_loss model saved: 0.054\n150 > Best val_loss model saved: 0.054\nepoch:150 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 47.0 seconds\n151 > Best val_loss model saved: 0.054\n152 > Best val_loss model saved: 0.054\n153 > Best val_loss model saved: 0.054\n154 > Best val_loss model saved: 0.054\n155 > Best val_loss model saved: 0.054\n156 > Best val_loss model saved: 0.054\n157 > Best val_loss model saved: 0.054\n158 > Best val_loss model saved: 0.054\n159 > Best val_loss model saved: 0.054\n160 > Best val_loss model saved: 0.054\nepoch:160 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 48.0 seconds\n161 > Best val_loss model saved: 0.054\n162 > Best val_loss model saved: 0.054\n163 > Best val_loss model saved: 0.054\n164 > Best val_loss model saved: 0.054\n165 > Best val_loss model saved: 0.054\n166 > Best val_loss model saved: 0.054\n167 > Best val_loss model saved: 0.054\n168 > Best val_loss model saved: 0.054\n169 > Best val_loss model saved: 0.054\n170 > Best val_loss model saved: 0.054\nepoch:170 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 51.0 seconds\n171 > Best val_loss model saved: 0.054\n172 > Best val_loss model saved: 0.054\n173 > Best val_loss model saved: 0.054\n174 > Best val_loss model saved: 0.054\n175 > Best val_loss model saved: 0.054\n176 > Best val_loss model saved: 0.054\n177 > Best val_loss model saved: 0.054\n178 > Best val_loss model saved: 0.054\n179 > Best val_loss model saved: 0.054\n180 > Best val_loss model saved: 0.054\nepoch:180 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 51.0 seconds\n181 > Best val_loss model saved: 0.054\n182 > Best val_loss model saved: 0.054\n183 > Best val_loss model saved: 0.054\n184 > Best val_loss model saved: 0.054\n185 > Best val_loss model saved: 0.054\n186 > Best val_loss model saved: 0.054\n187 > Best val_loss model saved: 0.054\n188 > Best val_loss model saved: 0.054\n189 > Best val_loss model saved: 0.054\n190 > Best val_loss model saved: 0.054\nepoch:190 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 51.0 seconds\n191 > Best val_loss model saved: 0.054\n192 > Best val_loss model saved: 0.054\n193 > Best val_loss model saved: 0.054\n194 > Best val_loss model saved: 0.054\n195 > Best val_loss model saved: 0.054\n196 > Best val_loss model saved: 0.054\n197 > Best val_loss model saved: 0.054\n198 > Best val_loss model saved: 0.054\n199 > Best val_loss model saved: 0.054\n200 > Best val_loss model saved: 0.054\nepoch:200 -> train_loss=0.10622,val_loss=0.05368 - 0.0 minutes 51.0 seconds\n201 > Best val_loss model saved: 0.054\n202 > Best val_loss model saved: 0.054\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# %load_ext tensorboard\n",
    "\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "from utils import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "last_loss = 0.0\n",
    "min_val_loss = np.inf\n",
    "patience_counter = 0\n",
    "early_stop_patience = 50\n",
    "best_model = None\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "output_path = '../outputs'\n",
    "tb_path = output_path+'/logs/runs'\n",
    "run_path = tb_path+'/run6.1_smallerLr'\n",
    "checkpoint_path = run_path+'/checkpoints'\n",
    "resume_training = False\n",
    "start_epoch = 0\n",
    "iter_count = 0\n",
    "\n",
    "if os.path.exists(run_path):\n",
    "    raise Exception(\"this experiment already exists!\")\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "\n",
    "writer = SummaryWriter(log_dir=run_path, comment='', purge_step=None, max_queue=1, flush_secs=50, filename_suffix='')\n",
    "\n",
    "# resume training on a saved model\n",
    "if resume_training:\n",
    "    prev_checkpoint_path = '../outputs/logs/runs/run16/checkpoints'  \n",
    "    model.load_state_dict(torch.load(prev_checkpoint_path+'/model_1589727955.160865.pt'))\n",
    "    optimizer.load_state_dict(torch.load(prev_checkpoint_path+'/optim_1589727955.160865.pt'))\n",
    "    lr_sched.load_state_dict(torch.load(prev_checkpoint_path+'/sched_1589727955.160865.pt')) \n",
    "    start_epoch = 500\n",
    "    writer.add_text('loaded saved model:', str(params))\n",
    "    print('loaded saved model', params)\n",
    "\n",
    "writer.add_text('run_change', 'Lr=0.001, rest same' + str(params))\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print('total epochs=', len(range(start_epoch, start_epoch+params['epochs'])))\n",
    "# epoch_bar = tqdm(range(epochs), ncols=12000)  # tqdm really slows down training! \n",
    "# with torch.autograd.detect_anomaly():\n",
    "for param_group in optimizer.param_groups:\n",
    "    print('lr-check', param_group['lr'])\n",
    "for epoch in range(start_epoch, start_epoch+params['epochs']):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    stime = time.time()\n",
    "    \n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        iter_count += 1\n",
    "        # get the inputs; data is a list of [inputs, dist_true]\n",
    "        model.train()\n",
    "        inputs, dist_true = data[0], data[1]\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, dist_true)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        last_loss = loss.item()\n",
    "\n",
    "        if not isinstance(lr_sched, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            lr_sched.step()\n",
    "\n",
    "    val_loss = evaluate(model, val_dl)\n",
    "    if isinstance(lr_sched, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "        lr_sched.step(val_loss)\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model = copy.deepcopy(model)\n",
    "        print(epoch,\"> Best val_loss model saved:\", round(val_loss, 3))\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    train_loss = running_loss/len(train_dl)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    writer.add_scalar('loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('loss/val', val_loss, epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        curr_lr = param_group['lr']\n",
    "    writer.add_scalar('monitor/lr', curr_lr, epoch)\n",
    "    if patience_counter > early_stop_patience:\n",
    "        print(\"Early stopping at epoch {}. current val_loss {}\".format(epoch, val_loss))\n",
    "        break\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(best_model.state_dict(), checkpoint_path+'/model_cp.pt')\n",
    "        torch.save(optimizer.state_dict(), checkpoint_path+'/optim_cp.pt')\n",
    "        torch.save(lr_sched.state_dict(), checkpoint_path+'/sched_cp.pt')\n",
    "        writer.add_text('checkpoint saved', 'at epoch='+str(epoch))\n",
    "        print(\"epoch:{} -> train_loss={},val_loss={} - {}\".format(epoch, round(train_loss, 5),                round(val_loss, 5), seconds_to_minutes(time.time()-stime)))\n",
    "    # epoch_bar.update(1)\n",
    "    # epoch_bar.set_description(desc=\"train_loss={},val_loss={},running_loss={}\".format(round(last_loss,3), round(val_loss,3), running_loss))\n",
    "\n",
    "print('Finished Training')\n",
    "ts = str(time.time())\n",
    "best_model_path = checkpoint_path+'/model_'+ts+'.pt'\n",
    "opt_save_path = checkpoint_path+'/optim_'+ts+'.pt'\n",
    "sched_save_path = checkpoint_path+'/sched_'+ts+'.pt'\n",
    "state_save_path = checkpoint_path+'/state_'+ts+'.pt'\n",
    "state = {'epoch': epoch+1,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optim_state': optimizer.state_dict(),\n",
    "        'last_train_loss': train_losses[-1],\n",
    "        'last_val_loss': val_losses[-1],\n",
    "        'total_iters': iter_count\n",
    "        }\n",
    "\n",
    "save_checkpoint(state, state_save_path)\n",
    "# sometimes loading from state dict is not wokring, so...\n",
    "torch.save(best_model.state_dict(), best_model_path)\n",
    "torch.save(optimizer.state_dict(), opt_save_path)\n",
    "torch.save(lr_sched.state_dict(), sched_save_path)\n",
    "# current best: run21(0.99 val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dl):\n",
    "    model.eval()\n",
    "    final_loss = 0.0\n",
    "    count = 0\n",
    "    y_hat = []\n",
    "    with torch.no_grad():\n",
    "        for data_cv in dl:\n",
    "            inputs, dist_true = data_cv[0], data_cv[1]\n",
    "            count += len(inputs)\n",
    "            outputs = model(inputs)\n",
    "            y_hat.extend(outputs.tolist())\n",
    "            loss = loss_fn(outputs, dist_true)\n",
    "            final_loss += loss.item()\n",
    "    return final_loss/len(dl), y_hat\n",
    "# the best_path was hardcoded here. so test again for previous runs 16-17\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "test_loss, y_hat = test(model, test_dl)\n",
    "print(test_loss)\n",
    "if scaler:\n",
    "    y_hat = scaler.inverse_transform(y_hat)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "y_hat[50:60], y_test[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show distance value wise precision (bar chart)\n",
    "# predicted values are less that real test samples because last samples from test are dropped # to maintain save batch size (drop_last=True)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_hat_ = np.array(y_hat).squeeze()\n",
    "y_test_ = y_test[:len(y_hat)]\n",
    "print(len(y_test), len(y_hat))\n",
    "dist_accuracies = []\n",
    "dist_counts = [] \n",
    "for i in range(1, 8):\n",
    "    mask = y_test_==i\n",
    "    dist_values = y_test_[mask]\n",
    "    dist_preds = np.round(y_hat_[mask])\n",
    "    # print(len(mask), len(dist_values), len(dist_preds))\n",
    "    # print(i, np.sum(np.equal(dist_values, dist_preds)), len(dist_values))\n",
    "    dist_accuracies.append(np.sum(dist_values == dist_preds)*100/len(dist_values))\n",
    "    dist_counts.append(len(dist_values))\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.subplot(2,1,1)\n",
    "plt.bar(range(1,8), dist_accuracies)\n",
    "for index, value in enumerate(dist_accuracies):\n",
    "    plt.text(index+0.8, value, str(np.round(value, 2))+'%')\n",
    "plt.title('distance-wise accuracy')\n",
    "plt.xlabel('distance values')\n",
    "plt.ylabel('accuracy')\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(range(1,8), dist_counts)\n",
    "for index, value in enumerate(dist_counts):\n",
    "    plt.text(index+0.8, value, str(value))\n",
    "plt.title('distance-wise count')\n",
    "plt.xlabel('distance values')\n",
    "plt.ylabel('counts')\n",
    "fig.tight_layout(pad=3.0)\n",
    "plt.show()\n",
    "writer.add_figure('test/results', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"shutdown /s /t 10\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to try\n",
    "* Next try one cycle lr sched -- \n",
    "* Distance values of 2 & 3 dominate the data. Best way to handle?\n",
    "* try batch normalization\n",
    "* normalize outputs?\n",
    "* try Mean Absolute Error (robust to large/small outliers) and Mean Sq log error.\n",
    "* are features good enough for prediction? Check it. May be try XGBoost for it.\n",
    "* stratified data\n",
    "* check one-cycle LR and loss correlation. Log it in tensorboard.\n",
    "* print out outputs to see why loss so high?\n",
    "* next try run20 with step size 8--------\n",
    "* try run23 without early stop\n",
    "#### from 37 checklist\n",
    "* try under sampling\n",
    "* Make sure your batches donâ€™t contain a single label -- batches skewed like this: [  58, 1795, 2514,  551,   78,    4], There are many batches where all are '1', e.g.:\n",
    "114 -- (tensor([1.], device='cuda:0'), tensor([5000], device='cuda:0'))\n",
    "115 -- (tensor([1.], device='cuda:0'), tensor([5000], device='cuda:0'))\n",
    "* large batch can reduce the generalization ability of the model\n",
    "* check model behaviour with random data and see if it's same\n",
    "* try zero mean and unit variance\n",
    "* train with just 1 or 2 examples and see if your network can learn to differentiate these. Then try more."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}